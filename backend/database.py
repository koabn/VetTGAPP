import pandas as pd
from typing import Tuple, Optional, List, Dict, Any, Union
from pathlib import Path
from logger import setup_logger
from config import DATABASE_FILE, DATABASE_ENCODING, DATABASE_SEPARATOR, DEBUG_LOG_FILE
from datetime import datetime
from nlp_utils import calculate_similarity

logger = setup_logger(__name__)

def log_debug(message: str) -> None:
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –æ—Ç–ª–∞–¥–æ—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ª–æ–≥–∞"""
    with open(DEBUG_LOG_FILE, 'a', encoding='utf-8') as f:
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        f.write(f"{timestamp} - {message}\n")

class Database:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        self.df: Optional[pd.DataFrame] = None
        self._load_database()
    
    def _load_database(self) -> None:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV —Ñ–∞–π–ª–∞"""
        try:
            self.df = pd.read_csv(
                DATABASE_FILE,
                sep=DATABASE_SEPARATOR,
                encoding=DATABASE_ENCODING
            )
            # –û—á–∏—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
            self.df.columns = self.df.columns.str.strip()
            # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            if 'Unnamed: 15' in self.df.columns:
                self.df = self.df.drop('Unnamed: 15', axis=1)
            
            logger.info(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {len(self.df)}")
            logger.debug(f"–ö–æ–ª–æ–Ω–∫–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {', '.join(self.df.columns)}")
            
        except FileNotFoundError:
            logger.error(f"–§–∞–π–ª –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {DATABASE_FILE}")
            raise
        except UnicodeDecodeError:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {DATABASE_FILE}")
            raise
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
            raise
    
    def get_drug_by_name(self, name: str) -> Optional[pd.Series]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–µ –ø–æ —Ç–æ—á–Ω–æ–º—É –Ω–∞–∑–≤–∞–Ω–∏—é
        
        Args:
            name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞
            
        Returns:
            Optional[pd.Series]: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–µ –∏–ª–∏ None, –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        try:
            matches = self.df[self.df['name'].str.lower() == name.lower()]
            return matches.iloc[0] if not matches.empty else None
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞ '{name}': {str(e)}")
            return None
    
    def search_drugs(self, query: str, similarity_threshold: float = 0.75) -> Tuple[Optional[pd.DataFrame], str]:
        """
        –ü–æ–∏—Å–∫ –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É —Å —É—á–µ—Ç–æ–º —Å—Ö–æ–∂–µ—Å—Ç–∏
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            similarity_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
            
        Returns:
            Tuple[Optional[pd.DataFrame], str]: (–ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç—ã, —Ç–∏–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞)
        """
        try:
            matches = []
            query_words = query.lower().split()
            log_debug(f"\n–ù–æ–≤—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
            log_debug(f"–†–∞–∑–±–∏—Ç—ã–µ —Å–ª–æ–≤–∞ –∑–∞–ø—Ä–æ—Å–∞: {query_words}")
            
            for _, row in self.df.iterrows():
                max_similarity = 0
                best_match_word = ""
                best_match_field = ""
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
                for query_word in query_words:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –µ–≥–æ —á–∞—Å—Ç–∏
                    if not pd.isna(row['name']):
                        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ –∑–∞–ø—è—Ç–æ–π
                        names = [name.strip().lower() for name in row['name'].split(',')]
                        for name in names:
                            similarity = calculate_similarity(query_word, name)
                            if similarity > max_similarity:
                                max_similarity = similarity
                                best_match_word = query_word
                                best_match_field = f"name: {name}"
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—Ä–≥–æ–≤—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
                    if not pd.isna(row['Trade_and_other_names']):
                        trade_names = [name.strip().lower() for name in row['Trade_and_other_names'].split(',')]
                        for trade_name in trade_names:
                            similarity = calculate_similarity(query_word, trade_name)
                            if similarity > max_similarity:
                                max_similarity = similarity
                                best_match_word = query_word
                                best_match_field = f"trade_name: {trade_name}"
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
                    if not pd.isna(row['Functional_classification']):
                        classifications = [c.strip().lower() for c in row['Functional_classification'].split(',')]
                        for classification in classifications:
                            similarity = calculate_similarity(query_word, classification)
                            if similarity > max_similarity:
                                max_similarity = similarity
                                best_match_word = query_word
                                best_match_field = f"classification: {classification}"
                
                # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ö–æ—Ä–æ—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                if max_similarity >= similarity_threshold:
                    matches.append((row, max_similarity))
                    log_debug(f"–ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¥–ª—è –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞ '{row['name']}':")
                    log_debug(f"  - –°–ª–æ–≤–æ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞: '{best_match_word}'")
                    log_debug(f"  - –°–æ–≤–ø–∞–ª–æ —Å –ø–æ–ª–µ–º: {best_match_field}")
                    log_debug(f"  - –°—Ö–æ–∂–µ—Å—Ç—å: {max_similarity:.3f}")
            
            if not matches:
                log_debug("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
                return None, 'not_found'
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            matches.sort(key=lambda x: x[1], reverse=True)
            log_debug("\n–û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–æ—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π (—Å—Ö–æ–∂–µ—Å—Ç—å >= 0.99)
            exact_matches = [(match, similarity) for match, similarity in matches if similarity >= 0.99]
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∏—Ö
            if exact_matches:
                matches = exact_matches
                log_debug("–ù–∞–π–¥–µ–Ω—ã —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (—Å—Ö–æ–∂–µ—Å—Ç—å >= 0.99), –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∏—Ö")
            
            for match, similarity in matches[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-5 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                log_debug(f"- {match['name']} (—Å—Ö–æ–∂–µ—Å—Ç—å: {similarity:.3f})")
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            seen = set()
            unique_matches = []
            for match, similarity in matches:
                if match['name'] not in seen:
                    seen.add(match['name'])
                    unique_matches.append(match)
            
            if len(unique_matches) > 1:
                log_debug(f"\n–ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤: {len(unique_matches)}")
                return pd.DataFrame(unique_matches), 'multiple'
            else:
                log_debug(f"\n–ù–∞–π–¥–µ–Ω –æ–¥–∏–Ω –ø—Ä–µ–ø–∞—Ä–∞—Ç: {unique_matches[0]['name']}")
                return unique_matches[0], 'single'
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤: {str(e)}")
            log_debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {str(e)}")
            return None, 'error'
    
    def get_drug_info(self, row: pd.Series, query_types: set, animal: Optional[str] = None) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–µ –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥
        
        Args:
            row: –°—Ç—Ä–æ–∫–∞ DataFrame —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–µ
            query_types: –¢–∏–ø—ã –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            animal: –¢–∏–ø –∂–∏–≤–æ—Ç–Ω–æ–≥–æ (cat/dog/None)
            
        Returns:
            str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–µ
        """
        try:
            info = []
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∂–∏–≤–æ—Ç–Ω–æ–≥–æ
            if animal:
                dosage_field = f"{animal.capitalize()}s_dosage"
                if not pd.isna(row[dosage_field]):
                    dosage = row[dosage_field].lower()
                    contraindicated_words = ['–ø—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω', '–Ω–µ–ª—å–∑—è', '–∑–∞–ø—Ä–µ—â–µ–Ω']
                    if any(word in dosage for word in contraindicated_words):
                        return f"‚õîÔ∏è {row['name']} –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω –¥–ª—è {'–∫–æ—à–µ–∫' if animal == 'cat' else '—Å–æ–±–∞–∫'}!\n\n‚ö†Ô∏è {row[dosage_field]}"
            
            # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            info.append(f"üìã –ù–∞–∑–≤–∞–Ω–∏–µ: {row['name']}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            if 'full' in query_types or not query_types:
                self._add_full_info(info, row, animal)
            else:
                self._add_specific_info(info, row, query_types, animal)
            
            return "\n".join(info)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–µ: {str(e)}")
            return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–µ"
    
    def _add_full_info(self, info: List[str], row: pd.Series, animal: Optional[str]) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–µ"""
        fields = {
            'name': ('üìã –ù–∞–∑–≤–∞–Ω–∏–µ', None),
            'Trade_and_other_names': ('üíä –¢–æ—Ä–≥–æ–≤—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è', None),
            'Functional_classification': ('üì¶ –ì—Ä—É–ø–ø–∞ –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤', None),
            'Pharmacology_and_Mechanism_of_Action': ('‚ö° –§–∞—Ä–º–∞–∫–æ–ª–æ–≥–∏—è –∏ –º–µ—Ö–∞–Ω–∏–∑–º –¥–µ–π—Å—Ç–≤–∏—è', '\n'),
            'Indications_and_Clinical_Uses': ('üéØ –ü–æ–∫–∞–∑–∞–Ω–∏—è –∏ –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ', '\n'),
            'Adverse_Reactions_and_Side_Effects': ('‚öïÔ∏è –ü–æ–±–æ—á–Ω—ã–µ —Ä–µ–∞–∫—Ü–∏–∏', '\n'),
            'Contraindications_and_Precautions': ('‚ö†Ô∏è –ü—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è –∏ –º–µ—Ä—ã –ø—Ä–µ–¥–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç–∏', '\n'),
            'Drug_Interactions': ('üîÑ –õ–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ', '\n'),
            'Instructions_for_Use': ('üíâ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é', '\n'),
            'Patient_Monitoring_and_Laboratory_Tests': ('üîç –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞—Ü–∏–µ–Ω—Ç–∞ –∏ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–µ –∞–Ω–∞–ª–∏–∑—ã', '\n'),
            'Formulations': ('üìù –õ–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã', '\n'),
            'Stability_and_Storage': ('üè† –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∏ —Ö—Ä–∞–Ω–µ–Ω–∏–µ', '\n')
        }
        
        for field, (emoji_text, prefix) in fields.items():
            if not pd.isna(row[field]) and row[field].strip():
                info.append(f"{prefix or ''}{emoji_text}: {row[field]}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∑–∏—Ä–æ–≤–∫–∏ –¥–ª—è –∂–∏–≤–æ—Ç–Ω—ã—Ö
        if animal == 'dog':
            if not pd.isna(row['Dogs_dosage']):
                info.append(f"\nüêï –î–æ–∑–∏—Ä–æ–≤–∫–∞ –¥–ª—è —Å–æ–±–∞–∫:\n{row['Dogs_dosage']}")
        elif animal == 'cat':
            if not pd.isna(row['Cats_dosage']):
                info.append(f"\nüê± –î–æ–∑–∏—Ä–æ–≤–∫–∞ –¥–ª—è –∫–æ—à–µ–∫:\n{row['Cats_dosage']}")
        else:
            if not pd.isna(row['Dogs_dosage']):
                info.append(f"\nüêï –î–æ–∑–∏—Ä–æ–≤–∫–∞ –¥–ª—è —Å–æ–±–∞–∫:\n{row['Dogs_dosage']}")
            if not pd.isna(row['Cats_dosage']):
                info.append(f"\nüê± –î–æ–∑–∏—Ä–æ–≤–∫–∞ –¥–ª—è –∫–æ—à–µ–∫:\n{row['Cats_dosage']}")
    
    def _add_specific_info(self, info: List[str], row: pd.Series, query_types: set, animal: Optional[str]) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–µ"""
        field_mapping = {
            'usage': ('Instructions_for_Use', 'üíâ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é'),
            'storage': ('Stability_and_Storage', 'üè† –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∏ —Ö—Ä–∞–Ω–µ–Ω–∏–µ'),
            'contraindications': ('Contraindications_and_Precautions', '‚ö†Ô∏è –ü—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è –∏ –º–µ—Ä—ã –ø—Ä–µ–¥–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç–∏'),
            'side_effects': ('Adverse_Reactions_and_Side_Effects', '‚öïÔ∏è –ü–æ–±–æ—á–Ω—ã–µ —Ä–µ–∞–∫—Ü–∏–∏'),
            'mechanism': ('Pharmacology_and_Mechanism_of_Action', '‚ö° –§–∞—Ä–º–∞–∫–æ–ª–æ–≥–∏—è –∏ –º–µ—Ö–∞–Ω–∏–∑–º –¥–µ–π—Å—Ç–≤–∏—è'),
            'interactions': ('Drug_Interactions', 'üîÑ –õ–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ'),
            'form': ('Formulations', 'üìù –õ–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã'),
            'monitoring': ('Patient_Monitoring_and_Laboratory_Tests', 'üîç –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞—Ü–∏–µ–Ω—Ç–∞ –∏ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–µ –∞–Ω–∞–ª–∏–∑—ã')
        }
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        if 'indications' in query_types and not pd.isna(row['Indications_and_Clinical_Uses']):
            info.append(f"\nüéØ –ü–æ–∫–∞–∑–∞–Ω–∏—è –∫ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é:\n{row['Indications_and_Clinical_Uses']}")
        
        if 'dosage' in query_types:
            if animal == 'dog' and not pd.isna(row['Dogs_dosage']):
                info.append(f"\nüêï –î–æ–∑–∏—Ä–æ–≤–∫–∞ –¥–ª—è —Å–æ–±–∞–∫:\n{row['Dogs_dosage']}")
            elif animal == 'cat' and not pd.isna(row['Cats_dosage']):
                info.append(f"\nüê± –î–æ–∑–∏—Ä–æ–≤–∫–∞ –¥–ª—è –∫–æ—à–µ–∫:\n{row['Cats_dosage']}")
            else:
                if not pd.isna(row['Dogs_dosage']):
                    info.append(f"\nüêï –î–æ–∑–∏—Ä–æ–≤–∫–∞ –¥–ª—è —Å–æ–±–∞–∫:\n{row['Dogs_dosage']}")
                if not pd.isna(row['Cats_dosage']):
                    info.append(f"\nüê± –î–æ–∑–∏—Ä–æ–≤–∫–∞ –¥–ª—è –∫–æ—à–µ–∫:\n{row['Cats_dosage']}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        for query_type, (field, emoji_text) in field_mapping.items():
            if query_type in query_types and not pd.isna(row[field]):
                info.append(f"\n{emoji_text}:\n{row[field]}")
    
    def compare_drugs(self, drug1_name: str, drug2_name: str) -> str:
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –¥–≤–∞ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ö —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏ —Ä–∞–∑–ª–∏—á–∏—è –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
        
        Args:
            drug1_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞
            drug2_name: –ù–∞–∑–≤–∞–Ω–∏–µ –≤—Ç–æ—Ä–æ–≥–æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞
            
        Returns:
            str: –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞—Ö
            drug1 = self.get_drug_by_name(drug1_name)
            drug2 = self.get_drug_by_name(drug2_name)
            
            if drug1 is None or drug2 is None:
                return "‚ùå –û–¥–∏–Ω –∏–ª–∏ –æ–±–∞ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"
            
            comparison = []
            comparison.append(f"üîÑ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤ {drug1['name']} –∏ {drug2['name']}:\n")
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
            if drug1['Functional_classification'] == drug2['Functional_classification']:
                comparison.append(f"üì¶ –ì—Ä—É–ø–ø–∞ –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤:\n‚úÖ –û–¥–∏–Ω–∞–∫–æ–≤–∞—è: {drug1['Functional_classification']}")
            else:
                comparison.append(f"üì¶ –ì—Ä—É–ø–ø–∞ –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤:\n- {drug1['name']}: {drug1['Functional_classification']}\n- {drug2['name']}: {drug2['Functional_classification']}")
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ–∫–∞–∑–∞–Ω–∏—è
            indications1 = drug1['Indications_and_Clinical_Uses']
            indications2 = drug2['Indications_and_Clinical_Uses']
            
            if not pd.isna(indications1) or not pd.isna(indications2):
                comparison.append("\nüéØ –ü–æ–∫–∞–∑–∞–Ω–∏—è –∫ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é:")
                if indications1 == indications2:
                    comparison.append(f"‚úÖ –û–¥–∏–Ω–∞–∫–æ–≤—ã–µ: {indications1}")
                else:
                    comparison.append(f"- {drug1['name']}: {indications1 if not pd.isna(indications1) else '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}")
                    comparison.append(f"- {drug2['name']}: {indications2 if not pd.isna(indications2) else '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}")
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –º–µ—Ö–∞–Ω–∏–∑–º –¥–µ–π—Å—Ç–≤–∏—è
            mech1 = drug1['Pharmacology_and_Mechanism_of_Action']
            mech2 = drug2['Pharmacology_and_Mechanism_of_Action']
            
            if not pd.isna(mech1) or not pd.isna(mech2):
                comparison.append("\n‚ö° –ú–µ—Ö–∞–Ω–∏–∑–º –¥–µ–π—Å—Ç–≤–∏—è:")
                if mech1 == mech2:
                    comparison.append(f"‚úÖ –û–¥–∏–Ω–∞–∫–æ–≤—ã–π: {mech1}")
                else:
                    comparison.append(f"- {drug1['name']}: {mech1 if not pd.isna(mech1) else '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}")
                    comparison.append(f"- {drug2['name']}: {mech2 if not pd.isna(mech2) else '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'}")
            
            return "\n".join(comparison)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤: {str(e)}")
            return "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤" 